{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9b7bafa4",
      "metadata": {
        "id": "9b7bafa4"
      },
      "source": [
        "# Neuroimaging full pipeline (MRI, fMRI)— teaching notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4797926",
      "metadata": {
        "id": "f4797926"
      },
      "source": [
        "## 0) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2d38d34",
      "metadata": {
        "id": "d2d38d34"
      },
      "outputs": [],
      "source": [
        "# Colab installs (uncomment if needed)\n",
        "!pip -q install nibabel scipy matplotlib scikit-learn\n",
        "!pip -q install antspyx\n",
        "\n",
        "import os, math\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import scipy\n",
        "import scipy.ndimage as ndi\n",
        "import scipy.interpolate as spi\n",
        "import scipy.fft as fft\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib\n",
        "import ants\n",
        "from scipy.stats import t as t_dist\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "print(\"numpy\", np.__version__)\n",
        "print(\"scipy\", scipy.__version__)\n",
        "print(\"nibabel\", nib.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1458b06c",
      "metadata": {
        "id": "1458b06c"
      },
      "source": [
        "## 1) Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee3694d",
      "metadata": {
        "id": "1ee3694d"
      },
      "outputs": [],
      "source": [
        "def show_slices(vol, title=\"\", slice_step=10, cmap=\"gray\", vmax=None):\n",
        "    z_slices = list(range(0, vol.shape[2], slice_step))\n",
        "    n = len(z_slices)\n",
        "    cols = min(6, n)\n",
        "    rows = int(np.ceil(n / cols))\n",
        "    plt.figure(figsize=(3*cols, 3*rows))\n",
        "    for i, z in enumerate(z_slices):\n",
        "        ax = plt.subplot(rows, cols, i+1)\n",
        "        ax.imshow(vol[:, :, z].T, origin=\"lower\", cmap=cmap, vmax=vmax)\n",
        "        ax.set_title(f\"z={z}\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def show_timeseries(ts, title=\"\", xlabel=\"time\", ylabel=\"value\"):\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.plot(ts)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def inspect_nifti(img: nib.Nifti1Image, name=\"image\"):\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(\"shape:\", img.shape)\n",
        "    print(\"dtype:\", img.get_data_dtype())\n",
        "    print(\"affine:\\n\", img.affine)\n",
        "    print(\"voxel sizes:\", img.header.get_zooms())\n",
        "\n",
        "def get_nii(url, local_fname='temp.nii.gz'):\n",
        "    # Download once\n",
        "    if not os.path.exists(local_fname):\n",
        "        print(\"Downloading Image...\")\n",
        "        urllib.request.urlretrieve(url, local_fname)\n",
        "\n",
        "    # Load with nibabel\n",
        "    img = ants.image_read(local_fname)\n",
        "    t1 = img.numpy()\n",
        "\n",
        "    print(\"Shape:\", t1.shape)\n",
        "    print(\"Voxel sizes:\", print(img.spacing))\n",
        "    print(img)\n",
        "    return img, t1\n",
        "\n",
        "def _spm_hrf(tr, length=32.0):\n",
        "    t = np.arange(0, length, tr)\n",
        "    def gamma_pdf(t, a, b):\n",
        "        return (t**(a-1) * np.exp(-t/b)) / (math.gamma(a) * (b**a) + 1e-12)\n",
        "    h = gamma_pdf(t, 6, 1) - 0.35*gamma_pdf(t, 16, 1)\n",
        "    h = h / (h.max() + 1e-12)\n",
        "    return h\n",
        "\n",
        "def _convolve_hrf(stim, tr):\n",
        "    h = _spm_hrf(tr)\n",
        "    return np.convolve(stim, h)[:len(stim)]\n",
        "\n",
        "def _make_epi_like_baseline(t1, mask, smooth_sigma=1.0):\n",
        "    \"\"\"\n",
        "    Convert T1-ish anatomy into something closer to an EPI baseline:\n",
        "    - compress dynamic range\n",
        "    - blur a bit\n",
        "    - add smooth multiplicative coil field\n",
        "    - add optional dropout region\n",
        "    \"\"\"\n",
        "    t1 = t1.astype(np.float32)\n",
        "    m = mask.astype(bool)\n",
        "\n",
        "    # robust normalize within mask\n",
        "    v = t1[m]\n",
        "    p1, p99 = np.percentile(v, [1, 99])\n",
        "    t = (t1 - p1) / (p99 - p1 + 1e-12)\n",
        "    t = np.clip(t, 0, 1)\n",
        "\n",
        "    # compress contrast (EPI has less stark tissue contrast than T1)\n",
        "    epi = 0.6 + 0.6*(t**0.5)  # monotonic, squashes highs a bit\n",
        "\n",
        "    # blur (EPI PSF + acquisition)\n",
        "    epi = ndi.gaussian_filter(epi, smooth_sigma)\n",
        "\n",
        "    # smooth coil/bias field (multiplicative)\n",
        "    coil = np.exp(0.15 * ndi.gaussian_filter(np.random.randn(*t1.shape), sigma=12))\n",
        "    epi = epi * coil\n",
        "\n",
        "    # optional dropout: a smooth \"hole\" (susceptibility-like)\n",
        "    nx, ny, nz = t1.shape\n",
        "    X, Y, Z = np.meshgrid(np.linspace(-1,1,nx), np.linspace(-1,1,ny), np.linspace(-1,1,nz), indexing=\"ij\")\n",
        "    dropout = np.exp(-((X-0.3)**2/(0.35**2) + (Y+0.2)**2/(0.30**2) + (Z-0.1)**2/(0.50**2)))\n",
        "    epi = epi * (1 - 0.35*dropout)  # reduce intensity in region\n",
        "\n",
        "    epi[~m] = 0\n",
        "    return epi.astype(np.float32)\n",
        "\n",
        "def simulate_realistic_fmri_from_t1(\n",
        "    t1_ds,\n",
        "    brain_mask_ds,\n",
        "    n_tr=200,\n",
        "    tr=2.0,\n",
        "    bold_psc=0.02,          # ~2% typical task PSC\n",
        "    smooth_fwhm_mm=6.0,\n",
        "    voxel_size_mm=2.0,      # set to your downsampled grid spacing\n",
        "    ar1=0.35,               # temporal autocorrelation\n",
        "    physio=True,\n",
        "    motion=True,\n",
        "    seed=0\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      fmri (X,Y,Z,T), stim (T,), task_reg (T,), activation_map (X,Y,Z), motion_params (T,6)\n",
        "    motion_params: [dx, dy, dz, rx, ry, rz] in vox and radians (toy)\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    t1 = t1_ds.astype(np.float32)\n",
        "    mask = brain_mask_ds.astype(bool)\n",
        "\n",
        "    # ---- baseline EPI-like anatomy ----\n",
        "    baseline = _make_epi_like_baseline(t1, mask, smooth_sigma=1.0)\n",
        "\n",
        "    # ---- activation map: smooth blob restricted to \"GM-ish\" (approx by mid intensities) ----\n",
        "    v = baseline[mask]\n",
        "    lo, hi = np.percentile(v, [35, 75])  # crude GM band\n",
        "    gm_like = mask & (baseline >= lo) & (baseline <= hi)\n",
        "\n",
        "    nx, ny, nz = baseline.shape\n",
        "    X, Y, Z = np.meshgrid(np.arange(nx), np.arange(ny), np.arange(nz), indexing=\"ij\")\n",
        "    cx, cy, cz = nx*0.55, ny*0.55, nz*0.55\n",
        "    act = (((X-cx)/(0.18*nx))**2 + ((Y-cy)/(0.16*ny))**2 + ((Z-cz)/(0.16*nz))**2) < 1.0\n",
        "    act = act & gm_like\n",
        "    act = ndi.gaussian_filter(act.astype(np.float32), sigma=1.2)\n",
        "    act = act / (act.max() + 1e-12)\n",
        "\n",
        "    # ---- task design + HRF ----\n",
        "    stim = np.zeros(n_tr, dtype=np.float32)\n",
        "    # simple blocks\n",
        "    for start in [20, 70, 120, 170]:\n",
        "        if start < n_tr:\n",
        "            stim[start:min(n_tr, start+12)] = 1.0\n",
        "    task_reg = _convolve_hrf(stim, tr)\n",
        "    task_reg = (task_reg - task_reg.mean()) / (task_reg.std() + 1e-12)\n",
        "\n",
        "    # ---- temporal components ----\n",
        "    t = np.arange(n_tr) * tr\n",
        "    drift = 0.01 * (t - t.mean()) / (t.max() + 1e-12)  # slow drift ~1%\n",
        "    phys = 0\n",
        "    if physio:\n",
        "        phys = (\n",
        "            0.004*np.sin(2*np.pi*0.25*t + 0.1) +  # ~15 bpm-ish (toy)\n",
        "            0.003*np.sin(2*np.pi*1.1*t + 0.7)     # faster component (toy)\n",
        "        ).astype(np.float32)\n",
        "\n",
        "    # AR(1) noise per voxel, but generated efficiently as white then filtered\n",
        "    # We'll do: e_t = ar1*e_{t-1} + w_t\n",
        "    # w_t spatially-smoothed for fMRI-like structure\n",
        "    sigma_spatial = (smooth_fwhm_mm / 2.355) / voxel_size_mm  # convert mm to vox\n",
        "    if sigma_spatial < 0.3:\n",
        "        sigma_spatial = 0.3\n",
        "\n",
        "    fmri = np.zeros((nx, ny, nz, n_tr), dtype=np.float32)\n",
        "\n",
        "    # initialize AR state\n",
        "    e_prev = np.zeros((nx, ny, nz), dtype=np.float32)\n",
        "\n",
        "    # motion params: dx,dy,dz in vox; rx,ry,rz in radians (toy)\n",
        "    motion_params = np.zeros((n_tr, 6), dtype=np.float32)\n",
        "    if motion:\n",
        "        motion_params[:, 0] = 0.4*np.sin(np.linspace(0, 6*np.pi, n_tr))      # dx\n",
        "        motion_params[:, 1] = 0.4*np.cos(np.linspace(0, 5*np.pi, n_tr))      # dy\n",
        "        motion_params[:, 2] = 0.2*np.sin(np.linspace(0, 4*np.pi, n_tr)+0.3)  # dz\n",
        "        motion_params[:, 3] = 0.01*np.sin(np.linspace(0, 3*np.pi, n_tr))     # rx\n",
        "        motion_params[:, 4] = 0.01*np.cos(np.linspace(0, 2*np.pi, n_tr))     # ry\n",
        "        motion_params[:, 5] = 0.01*np.sin(np.linspace(0, 2*np.pi, n_tr)+0.2) # rz\n",
        "\n",
        "    # ---- generate time series ----\n",
        "    for i in range(n_tr):\n",
        "        # BOLD modulation as percent signal change in activation region\n",
        "        bold = 1.0 + bold_psc * task_reg[i] * act\n",
        "\n",
        "        # global-ish fluctuations\n",
        "        g = (drift[i] + phys[i]).astype(np.float32)\n",
        "\n",
        "        # spatially structured innovation noise\n",
        "        w = rng.standard_normal((nx, ny, nz)).astype(np.float32)\n",
        "        w = ndi.gaussian_filter(w, sigma=sigma_spatial)\n",
        "        w *= 0.015  # noise amplitude (~1–2% typical)\n",
        "\n",
        "        # AR(1)\n",
        "        e = ar1 * e_prev + w\n",
        "        e_prev = e\n",
        "\n",
        "        vol = baseline * bold * (1.0 + g) + baseline * e\n",
        "        vol[~mask] = 0\n",
        "\n",
        "        # apply motion (translations only by default; rotations are a “conceptual placeholder”)\n",
        "        if motion:\n",
        "            dx, dy, dz = motion_params[i, 0], motion_params[i, 1], motion_params[i, 2]\n",
        "            vol = ndi.shift(vol, shift=(dx, dy, dz), order=1, mode=\"nearest\")\n",
        "\n",
        "        fmri[..., i] = vol.astype(np.float32)\n",
        "\n",
        "    return fmri, stim, task_reg.astype(np.float32), act.astype(np.float32), motion_params\n",
        "\n",
        "def make_smooth_displacement_field(shape, max_disp_vox=1.5, smooth_sigma=12.0, seed=0):\n",
        "    \"\"\"Smooth displacement field in VOXELS (use for EPI distortion).\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    f = rng.standard_normal(shape).astype(np.float32)\n",
        "    f = ndi.gaussian_filter(f, smooth_sigma)\n",
        "    f = f / (np.max(np.abs(f)) + 1e-12)\n",
        "    return (max_disp_vox * f).astype(np.float32)\n",
        "\n",
        "def warp_y(vol, dy_vox, order=1, mode=\"nearest\"):\n",
        "    \"\"\"Warp along y (phase-encode) using dy(x,y,z) in voxels.\"\"\"\n",
        "    nx, ny, nz = vol.shape\n",
        "    X, Y, Z = np.meshgrid(np.arange(nx), np.arange(ny), np.arange(nz), indexing=\"ij\")\n",
        "    coords = [X.astype(np.float32), (Y.astype(np.float32) + dy_vox), Z.astype(np.float32)]\n",
        "    return ndi.map_coordinates(vol, coords, order=order, mode=mode).astype(np.float32)\n",
        "\n",
        "def apply_dropout_from_field(vol, dy_vox, mask, strength=0.30):\n",
        "    \"\"\"Toy susceptibility dropout correlated with |dy|.\"\"\"\n",
        "    m = mask.astype(bool)\n",
        "    d = np.abs(dy_vox)\n",
        "    scale = np.percentile(d[m], 99) + 1e-12\n",
        "    a = np.clip(d / scale, 0, 1)  # 0..1\n",
        "    out = vol.copy()\n",
        "    out[m] = out[m] * (1 - strength * a[m])\n",
        "    out[~m] = 0\n",
        "    return out.astype(np.float32)\n",
        "\n",
        "def slice_acquisition_offsets(n_slices, tr, scheme=\"interleaved\"):\n",
        "    if scheme == \"ascending\":\n",
        "        order = list(range(n_slices))\n",
        "    elif scheme == \"descending\":\n",
        "        order = list(range(n_slices-1, -1, -1))\n",
        "    elif scheme == \"interleaved\":\n",
        "        order = list(range(0, n_slices, 2)) + list(range(1, n_slices, 2))\n",
        "    else:\n",
        "        raise ValueError(\"scheme must be ascending/descending/interleaved\")\n",
        "\n",
        "    offsets = np.zeros(n_slices, dtype=np.float32)\n",
        "    for i, sl in enumerate(order):\n",
        "        offsets[sl] = (i / n_slices) * tr\n",
        "    return offsets\n",
        "\n",
        "def apply_slice_timing(fmri_4d, tr, slice_axis=2, scheme=\"interleaved\", ref_slice=0):\n",
        "    data = fmri_4d.astype(np.float32)\n",
        "    n_tr = data.shape[-1]\n",
        "    n_slices = data.shape[slice_axis]\n",
        "\n",
        "    offsets = slice_acquisition_offsets(n_slices, tr, scheme=scheme)\n",
        "    dt = offsets - offsets[ref_slice]  # relative to ref slice\n",
        "    t = np.arange(n_tr) * tr\n",
        "\n",
        "    out = np.zeros_like(data)\n",
        "    for sl in range(n_slices):\n",
        "        slicer = [slice(None)] * 4\n",
        "        slicer[slice_axis] = sl\n",
        "        slab = data[tuple(slicer)]               # (x,y,t) for slice_axis=2\n",
        "        slabT = np.moveaxis(slab, -1, 0)         # (T,x,y)\n",
        "        T, A, B = slabT.shape\n",
        "        flat = slabT.reshape(T, -1)              # (T,N)\n",
        "\n",
        "        t_new = np.clip(t + dt[sl], t[0], t[-1])\n",
        "        interp = spi.interp1d(t, flat, kind=\"linear\", axis=0,\n",
        "                              bounds_error=False, fill_value=\"extrapolate\")\n",
        "        shifted = interp(t_new).reshape(T, A, B)\n",
        "        out[tuple(slicer)] = np.moveaxis(shifted, 0, -1).astype(np.float32)\n",
        "\n",
        "    return out, offsets\n",
        "\n",
        "def add_distortion_and_slice_timing(\n",
        "    fmri_4d, brain_mask, tr,\n",
        "    max_disp_vox=1.5, smooth_sigma=12.0, dropout_strength=0.30,\n",
        "    seed=0, st_scheme=\"interleaved\", slice_axis=2, ref_slice=0\n",
        "):\n",
        "    # Distortion field (dy in voxels)\n",
        "    dy = make_smooth_displacement_field(fmri_4d.shape[:3], max_disp_vox=max_disp_vox,\n",
        "                                        smooth_sigma=smooth_sigma, seed=seed)\n",
        "\n",
        "    out = np.zeros_like(fmri_4d, dtype=np.float32)\n",
        "    for t in range(fmri_4d.shape[-1]):\n",
        "        v = warp_y(fmri_4d[..., t], dy, order=1)\n",
        "        v = apply_dropout_from_field(v, dy, brain_mask, strength=dropout_strength)\n",
        "        out[..., t] = v\n",
        "\n",
        "    # Slice timing “as acquired”\n",
        "    out_st, offsets = apply_slice_timing(out, tr=tr, slice_axis=slice_axis,\n",
        "                                         scheme=st_scheme, ref_slice=ref_slice)\n",
        "    return out_st, dy, offsets\n",
        "\n",
        "def plot_voxel_timeseries(\n",
        "    fmri_4d,\n",
        "    coord=None,\n",
        "    brain_mask=None,\n",
        "    tr=2.0,\n",
        "    title=\"Voxel time series\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot the time series from a single voxel.\n",
        "    coord: (x,y,z). If None, pick center of mass of brain_mask.\n",
        "    \"\"\"\n",
        "    if coord is None:\n",
        "        if brain_mask is None:\n",
        "            raise ValueError(\"Provide coord or brain_mask\")\n",
        "        idx = np.array(np.where(brain_mask > 0))\n",
        "        coord = tuple(np.mean(idx, axis=1).astype(int))\n",
        "\n",
        "    ts = fmri_4d[coord[0], coord[1], coord[2], :]\n",
        "    t = np.arange(len(ts)) * tr\n",
        "\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.plot(t, ts, lw=1)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Signal\")\n",
        "    plt.title(f\"{title} @ voxel {coord}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_roi_timeseries(\n",
        "    fmri_4d,\n",
        "    roi_mask,\n",
        "    tr=2.0,\n",
        "    title=\"ROI mean time series\",\n",
        "    normalize=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot mean ± SD time series from an ROI.\n",
        "    \"\"\"\n",
        "    data = fmri_4d[roi_mask > 0]  # (nvox, T)\n",
        "    mean_ts = data.mean(axis=0)\n",
        "    std_ts = data.std(axis=0)\n",
        "\n",
        "    if normalize:\n",
        "        mean_ts = (mean_ts - mean_ts.mean()) / (mean_ts.std() + 1e-12)\n",
        "\n",
        "    t = np.arange(mean_ts.size) * tr\n",
        "\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.plot(t, mean_ts, lw=2, label=\"Mean\")\n",
        "    plt.fill_between(t, mean_ts - std_ts, mean_ts + std_ts, alpha=0.2, label=\"±1 SD\")\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Normalized signal\" if normalize else \"Signal\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_roi_vs_design(\n",
        "    fmri_4d,\n",
        "    roi_mask,\n",
        "    design,\n",
        "    tr=2.0,\n",
        "    title=\"ROI vs design\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Overlay ROI-mean time series and design regressor.\n",
        "    \"\"\"\n",
        "    data = fmri_4d[roi_mask > 0]\n",
        "    ts = data.mean(axis=0)\n",
        "    ts = (ts - ts.mean()) / (ts.std() + 1e-12)\n",
        "\n",
        "    design = design.astype(float)\n",
        "    design = (design - design.mean()) / (design.std() + 1e-12)\n",
        "\n",
        "    t = np.arange(ts.size) * tr\n",
        "\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.plot(t, ts, lw=2, label=\"ROI mean (z-scored)\")\n",
        "    plt.plot(t, design, lw=2, label=\"Design (z-scored)\", alpha=0.8)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Z-score\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def slice_timing_correct(fmri_4d, tr, slice_axis=2, interleaved=True, ref_slice=0):\n",
        "    n_tr = fmri_4d.shape[-1]\n",
        "    n_slices = fmri_4d.shape[slice_axis]\n",
        "\n",
        "    if interleaved:\n",
        "        order = list(range(0, n_slices, 2)) + list(range(1, n_slices, 2))\n",
        "    else:\n",
        "        order = list(range(n_slices))\n",
        "\n",
        "    slice_times = np.zeros(n_slices, float)\n",
        "    for i, sl in enumerate(order):\n",
        "        slice_times[sl] = (i / n_slices) * tr\n",
        "\n",
        "    t_ref = slice_times[ref_slice]\n",
        "    dt = slice_times - t_ref\n",
        "    t = np.arange(n_tr) * tr\n",
        "\n",
        "    out = np.zeros_like(fmri_4d)\n",
        "    for sl in range(n_slices):\n",
        "        slicer = [slice(None)] * 4\n",
        "        slicer[slice_axis] = sl\n",
        "        slab = fmri_4d[tuple(slicer)]  # (x,y,t)\n",
        "        slab2 = np.moveaxis(slab, -1, 0)  # (t,x,y)\n",
        "        T, X, Y = slab2.shape\n",
        "        slab_flat = slab2.reshape(T, -1)\n",
        "        t_new = np.clip(t + dt[sl], t[0], t[-1])\n",
        "        interp = spi.interp1d(t, slab_flat, kind=\"linear\", axis=0, bounds_error=False, fill_value=\"extrapolate\")\n",
        "        slab_corr = interp(t_new).reshape(T, X, Y)\n",
        "        slab_corr = np.moveaxis(slab_corr, 0, -1)  # (x,y,t)\n",
        "        out[tuple(slicer)] = slab_corr.astype(np.float32)\n",
        "    return out\n",
        "\n",
        "def _parabolic_subpixel(fm1, f0, fp1, eps=1e-12):\n",
        "    \"\"\"\n",
        "    Subpixel peak offset from three samples of a parabola:\n",
        "    offset = (fm1 - fp1) / (2*(fm1 - 2*f0 + fp1))\n",
        "    Result is in [-0.5, 0.5] typically.\n",
        "    \"\"\"\n",
        "    denom = 2.0 * (fm1 - 2.0*f0 + fp1)\n",
        "    if abs(denom) < eps:\n",
        "        return 0.0\n",
        "    return float((fm1 - fp1) / denom)\n",
        "\n",
        "def phase_correlation_shift_subpixel(ref, mov, mask=None, window=True, eps=1e-12):\n",
        "    \"\"\"\n",
        "    Estimate translation (in voxels) between ref and mov using phase correlation,\n",
        "    with sub-voxel refinement via 1D parabolic fits around the correlation peak.\n",
        "\n",
        "    Returns shift s such that: ref ≈ shift(mov, s)\n",
        "    \"\"\"\n",
        "    a = ref.astype(np.float32, copy=False)\n",
        "    b = mov.astype(np.float32, copy=False)\n",
        "\n",
        "    if mask is not None:\n",
        "        m = mask.astype(np.float32, copy=False)\n",
        "        a = a * m\n",
        "        b = b * m\n",
        "\n",
        "    # Optional: taper edges to reduce boundary artifacts\n",
        "    if window:\n",
        "        wx = np.hanning(a.shape[0]).astype(np.float32)\n",
        "        wy = np.hanning(a.shape[1]).astype(np.float32)\n",
        "        wz = np.hanning(a.shape[2]).astype(np.float32)\n",
        "        w = wx[:, None, None] * wy[None, :, None] * wz[None, None, :]\n",
        "        a = a * w\n",
        "        b = b * w\n",
        "\n",
        "    Fa = fft.fftn(a)\n",
        "    Fb = fft.fftn(b)\n",
        "    R = Fa * np.conj(Fb)\n",
        "    R /= np.maximum(np.abs(R), eps)\n",
        "    cc = np.real(fft.ifftn(R))\n",
        "\n",
        "    peak = np.unravel_index(np.argmax(cc), cc.shape)\n",
        "    peak = list(peak)\n",
        "\n",
        "    # Convert peak index to signed integer shift\n",
        "    shifts = np.array(peak, dtype=np.float64)\n",
        "    for i, n in enumerate(cc.shape):\n",
        "        if shifts[i] > n / 2:\n",
        "            shifts[i] -= n\n",
        "\n",
        "    # Subpixel refinement: fit parabola around peak along each axis\n",
        "    sub = np.zeros(3, dtype=np.float64)\n",
        "    for ax in range(3):\n",
        "        p = peak[ax]\n",
        "        n = cc.shape[ax]\n",
        "        pm1 = (p - 1) % n\n",
        "        pp1 = (p + 1) % n\n",
        "\n",
        "        if ax == 0:\n",
        "            fm1, f0, fp1 = cc[pm1, peak[1], peak[2]], cc[p, peak[1], peak[2]], cc[pp1, peak[1], peak[2]]\n",
        "        elif ax == 1:\n",
        "            fm1, f0, fp1 = cc[peak[0], pm1, peak[2]], cc[peak[0], p, peak[2]], cc[peak[0], pp1, peak[2]]\n",
        "        else:\n",
        "            fm1, f0, fp1 = cc[peak[0], peak[1], pm1], cc[peak[0], peak[1], p], cc[peak[0], peak[1], pp1]\n",
        "\n",
        "        sub[ax] = _parabolic_subpixel(fm1, f0, fp1, eps=eps)\n",
        "\n",
        "    return shifts + sub  # fractional voxels\n",
        "\n",
        "def motion_correct_4d(fmri_4d, ref_index=0, brain_mask=None):\n",
        "    ref = fmri_4d[..., ref_index]\n",
        "    out = np.zeros_like(fmri_4d, dtype=np.float32)\n",
        "    est = np.zeros((fmri_4d.shape[-1], 3), dtype=np.float64)\n",
        "\n",
        "    for t in range(fmri_4d.shape[-1]):\n",
        "        s = phase_correlation_shift_subpixel(ref, fmri_4d[..., t], mask=brain_mask, window=True)\n",
        "        est[t] = s\n",
        "        out[..., t] = ndi.shift(fmri_4d[..., t], shift=tuple(s), order=1, mode=\"nearest\")\n",
        "\n",
        "    return out, est\n",
        "\n",
        "def spatial_smooth_4d(fmri_4d, fwhm_mm=6.0, voxel_size_mm=1.0):\n",
        "    sigma_mm = fwhm_mm / 2.355\n",
        "    sigma_vox = sigma_mm / voxel_size_mm\n",
        "    out = np.zeros_like(fmri_4d)\n",
        "    for t in range(fmri_4d.shape[-1]):\n",
        "        out[..., t] = ndi.gaussian_filter(fmri_4d[..., t], sigma=sigma_vox)\n",
        "    return out\n",
        "\n",
        "def detrend_timecourse(x):\n",
        "    t = np.arange(len(x))\n",
        "    A = np.column_stack([np.ones_like(t), t])\n",
        "    beta = np.linalg.lstsq(A, x, rcond=None)[0]\n",
        "    return x - A @ beta\n",
        "\n",
        "def bandpass_fft(x, tr, low=0.01, high=0.12):\n",
        "    n = len(x)\n",
        "    freqs = fft.fftfreq(n, d=tr)\n",
        "    X = fft.fft(x)\n",
        "    keep = (np.abs(freqs) >= low) & (np.abs(freqs) <= high)\n",
        "    return np.real(fft.ifft(X * keep))\n",
        "\n",
        "def filter_voxels(fmri_4d, mask, tr, low=0.01, high=0.12, max_vox=10000):\n",
        "    out = np.zeros_like(fmri_4d)\n",
        "    vox = np.array(np.where(mask > 0)).T\n",
        "    if vox.shape[0] > max_vox:\n",
        "        vox = vox[np.random.choice(vox.shape[0], size=max_vox, replace=False)]\n",
        "        print(\"Downsampling to\", vox.shape[0], \"voxels for speed\")\n",
        "    for x,y,z in vox:\n",
        "        ts = detrend_timecourse(fmri_4d[x,y,z,:])\n",
        "        ts = bandpass_fft(ts, tr=tr, low=low, high=high)\n",
        "        out[x,y,z,:] = ts.astype(np.float32)\n",
        "    return out\n",
        "\n",
        "def fdr_bh(pvals, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Benjamini–Hochberg FDR correction.\n",
        "    Returns boolean array of significant tests.\n",
        "    \"\"\"\n",
        "    pvals = np.asarray(pvals)\n",
        "    n = pvals.size\n",
        "\n",
        "    order = np.argsort(pvals)\n",
        "    p_sorted = pvals[order]\n",
        "\n",
        "    thresh = alpha * np.arange(1, n+1) / n\n",
        "    passed = p_sorted <= thresh\n",
        "\n",
        "    if not np.any(passed):\n",
        "        return np.zeros_like(pvals, dtype=bool)\n",
        "\n",
        "    k = np.max(np.where(passed))\n",
        "    cutoff = p_sorted[k]\n",
        "\n",
        "    return pvals <= cutoff\n",
        "\n",
        "def seed_correlation_map(fmri_4d, seed_mask, brain_mask):\n",
        "    seed_ts = fmri_4d[seed_mask > 0].mean(axis=0)\n",
        "    seed_ts = (seed_ts - seed_ts.mean()) / (seed_ts.std() + 1e-12)\n",
        "\n",
        "    corr = np.zeros(brain_mask.shape, np.float32)\n",
        "    idx = np.where(brain_mask > 0)\n",
        "    for x,y,z in zip(*idx):\n",
        "        ts = fmri_4d[x,y,z,:]\n",
        "        ts = (ts - ts.mean()) / (ts.std() + 1e-12)\n",
        "        corr[x,y,z] = np.dot(seed_ts, ts) / len(ts)\n",
        "    return corr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b31e978",
      "metadata": {
        "id": "3b31e978"
      },
      "source": [
        "# PART A — Structural MRI (T1w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc8ca43",
      "metadata": {
        "id": "1cc8ca43"
      },
      "source": [
        "## 2) Download sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a035c3d",
      "metadata": {
        "id": "1a035c3d"
      },
      "outputs": [],
      "source": [
        "t1_img, t1_arr = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/T1.nii.gz\", local_fname='Test_T1.nii.gz')\n",
        "show_slices(t1_arr, \"Synthetic T1w (biased + noisy)\", slice_step=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5914d4bc",
      "metadata": {
        "id": "5914d4bc"
      },
      "source": [
        "## 3) Denoising + bias correction\n",
        "Tustison, N. J., Avants, B. B., Cook, P. A., Zheng, Y., Egan, A., Yushkevich, P. A., & Gee, J. C. (2010). N4ITK: improved N3 bias correction. IEEE transactions on medical imaging, 29(6), 1310–1320. https://doi.org/10.1109/TMI.2010.2046908\n",
        "\n",
        "J. V. Manjon, P. Coupe, Luis Marti-Bonmati, D. L. Collins, and M. Robles. Adaptive Non-Local Means Denoising of MR Images With Spatially Varying Noise Levels, Journal of Magnetic Resonance Imaging, 31:192-203, June 2010."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4544acd",
      "metadata": {
        "id": "c4544acd"
      },
      "outputs": [],
      "source": [
        "# t1_debiased = t1_img.n4_bias_field_correction()\n",
        "# t1_debiased_arr = t1_debiased.numpy()\n",
        "# show_slices(t1_debiased_arr, \"N4 Debiased T1w\", slice_step=20)\n",
        "# ants.image_write(t1_debiased, \"T1_debiased.nii.gz\")\n",
        "t1_debiased, t1_debiased_arr = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/T1_debiased.nii.gz\",\n",
        "                                       local_fname='Test_T1_debiased.nii.gz')\n",
        "\n",
        "# t1_debiased_denoised = ants.denoise_image(t1_debiased)\n",
        "# t1_debiased_denoised_arr = t1_debiased_denoised.numpy()\n",
        "# show_slices(t1_debiased_denoised_arr, \"N4 Debiased + Denoised T1w\", slice_step=20)\n",
        "# ants.image_write(t1_debiased_denoised, \"T1_debiased_denoised.nii.gz\")\n",
        "t1_debiased_denoised, t1_debiased_denoised_arr = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/T1_debiased_denoised.nii.gz\",\n",
        "                                                         local_fname='Test_T1_debiased_denoised.nii.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb659b9",
      "metadata": {
        "id": "1fb659b9"
      },
      "outputs": [],
      "source": [
        "show_slices(t1_arr, \"Original T1w\", slice_step=20)\n",
        "show_slices(t1_debiased_arr, \"N4 Debiased T1w\", slice_step=20)\n",
        "show_slices(t1_debiased_denoised_arr, \"N4 Debiased + Denoised T1w\", slice_step=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d2c5b30",
      "metadata": {
        "id": "6d2c5b30"
      },
      "source": [
        "## 4) Registration + Brain extraction + tissue segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3adc8d",
      "metadata": {
        "id": "fe3adc8d"
      },
      "outputs": [],
      "source": [
        "mni_img, mni_arr = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/mni_icbm152_t1_tal_nlin_asym_09c.nii\",\n",
        "                           local_fname='Test_mni_icbm152_t1_tal_nlin_asym_09c.nii')\n",
        "\n",
        "mni_brain_mask, mni_brain_mask_arr = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/mni_icbm152_t1_tal_nlin_asym_09c_bet_mask.nii.gz\",\n",
        "                                             local_fname='Test_mni_icbm152_t1_tal_nlin_asym_09c_bet_mask.nii.gz')\n",
        "\n",
        "mni_gm_mask, mni_gm_mask_arr = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/mni_icbm152_gm_tal_nlin_asym_09c.nii\",\n",
        "                                       local_fname='Test_mni_icbm152_gm_tal_nlin_asym_09c.nii')\n",
        "\n",
        "mni_wm_mask, mni_wm_mask_arr = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/mni_icbm152_wm_tal_nlin_asym_09c.nii\",\n",
        "                                       local_fname='Test_mni_icbm152_wm_tal_nlin_asym_09c.nii')\n",
        "\n",
        "mni_csf_mask, mni_csf_mask_arr = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/mni_icbm152_csf_tal_nlin_asym_09c.nii\",\n",
        "                                         local_fname='Test_mni_icbm152_csf_tal_nlin_asym_09c.nii')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6483dcf6",
      "metadata": {
        "id": "6483dcf6"
      },
      "outputs": [],
      "source": [
        "# mni2t1 = ants.registration(fixed=t1_debiased_denoised, moving=mni_img)\n",
        "# mni2t1_warped = mni2t1['warpedmovout']\n",
        "mni2t1_warped = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/mni2t1_warped.nii.gz\",\n",
        "                                         local_fname='Test_mni2t1.nii.gz')\n",
        "t1_debiased_denoised.plot(overlay=mni2t1_warped, overlay_alpha=0.5, overlay_cmap='jet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86397859",
      "metadata": {
        "id": "86397859"
      },
      "outputs": [],
      "source": [
        "gm2t1_warped = ants.apply_transforms(fixed=t1_debiased_denoised, moving=mni_gm_mask, transformlist=mni2t1['fwdtransforms'], interpolator='nearestNeighbor')\n",
        "wm2t1_warped = ants.apply_transforms(fixed=t1_debiased_denoised, moving=mni_wm_mask, transformlist=mni2t1['fwdtransforms'], interpolator='nearestNeighbor')\n",
        "csf2t1_warped = ants.apply_transforms(fixed=t1_debiased_denoised, moving=mni_csf_mask, transformlist=mni2t1['fwdtransforms'], interpolator='nearestNeighbor')\n",
        "brain_mask_warped = ants.apply_transforms(fixed=t1_debiased_denoised, moving=mni_brain_mask, transformlist=mni2t1['fwdtransforms'], interpolator='nearestNeighbor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e17753",
      "metadata": {
        "id": "80e17753"
      },
      "outputs": [],
      "source": [
        "t1_brain = t1_debiased_denoised * brain_mask_warped\n",
        "t1_brain.plot(axis=2, overlay=gm2t1_warped, overlay_alpha=0.5, overlay_cmap='Reds')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0f6c3d0",
      "metadata": {
        "id": "d0f6c3d0"
      },
      "source": [
        "# PART B — fMRI pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad0e91e",
      "metadata": {
        "id": "cad0e91e"
      },
      "source": [
        "## 6) Simulate fMRI (task + motion + noise + slice timing + distortions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d3cef0",
      "metadata": {
        "id": "79d3cef0"
      },
      "outputs": [],
      "source": [
        "t1_downsample = ants.resample_image(t1_debiased_denoised, [3.0, 3.0, 3.0], use_voxels=False, interp_type=1)\n",
        "t1_for_fmri_arr = t1_downsample.numpy()\n",
        "brain_mask_downsample = ants.resample_image(brain_mask_warped, [3.0, 3.0, 3.0], use_voxels=False, interp_type=0)\n",
        "brain_mask_for_fmri_arr = brain_mask_downsample.numpy()\n",
        "\n",
        "fmri, stim, task_reg, act_map, mot = simulate_realistic_fmri_from_t1(\n",
        "    t1_for_fmri_arr, brain_mask_for_fmri_arr,\n",
        "    n_tr=180, tr=2.0,\n",
        "    bold_psc=0.02,\n",
        "    smooth_fwhm_mm=6.0,\n",
        "    voxel_size_mm=3.0,   # set correctly!\n",
        "    seed=1\n",
        ")\n",
        "\n",
        "# Visual sanity check: a few timepoints\n",
        "show_slices(fmri[..., 10], \"fMRI TR=10\", slice_step=8)\n",
        "show_slices(fmri[..., 80], \"fMRI TR=80\", slice_step=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d098f75",
      "metadata": {
        "id": "8d098f75"
      },
      "outputs": [],
      "source": [
        "fmri_dist_st, dy_field, slice_offsets = add_distortion_and_slice_timing(\n",
        "    fmri, brain_mask_for_fmri_arr, tr=2.0,\n",
        "    max_disp_vox=1.5,        # ~4.5 mm peak\n",
        "    smooth_sigma=12.0,       # smooth field\n",
        "    dropout_strength=0.30,   # moderate dropout\n",
        "    seed=0,\n",
        "    st_scheme=\"interleaved\",\n",
        "    slice_axis=2,            # typical z-slices\n",
        "    ref_slice=0\n",
        ")\n",
        "\n",
        "show_slices(fmri_dist_st[..., 10], \"Distorted + slice-timed (TR=10)\", slice_step=6)\n",
        "show_slices(fmri_dist_st[..., 80], \"Distorted + slice-timed (TR=80)\", slice_step=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "164e7022",
      "metadata": {
        "id": "164e7022"
      },
      "outputs": [],
      "source": [
        "plot_voxel_timeseries(\n",
        "    fmri_dist_st,\n",
        "    brain_mask=brain_mask_for_fmri_arr,\n",
        "    tr=2.0,\n",
        "    title=\"Single voxel (raw distorted)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd8b2eb",
      "metadata": {
        "id": "7dd8b2eb"
      },
      "outputs": [],
      "source": [
        "left_caudate_putamen = get_nii(\n",
        "    url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/Left_Caud_Put.nii.gz\",\n",
        "    local_fname='Test_Left_Caud_Put.nii.gz')[0]\n",
        "\n",
        "left_caudate_putamen_in_t1 = ants.apply_transforms(\n",
        "    fixed=t1_debiased_denoised,\n",
        "    moving=left_caudate_putamen,\n",
        "    transformlist=mni2t1['fwdtransforms'],\n",
        "    interpolator='nearestNeighbor'\n",
        ")\n",
        "\n",
        "left_caudate_putamen_in_fmri = ants.resample_image_to_target(\n",
        "    left_caudate_putamen_in_t1,\n",
        "    t1_downsample,\n",
        "    interp_type=0\n",
        ")\n",
        "\n",
        "left_caudate_putamen_in_fmri_arr = left_caudate_putamen_in_fmri.numpy()\n",
        "\n",
        "plot_roi_timeseries(\n",
        "    fmri_dist_st,\n",
        "    left_caudate_putamen_in_fmri_arr,   # your true activation region\n",
        "    tr=2.0,\n",
        "    title=\"Activation ROI (mean ± SD)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3450ea08",
      "metadata": {
        "id": "3450ea08"
      },
      "outputs": [],
      "source": [
        "plot_roi_vs_design(\n",
        "    fmri_dist_st,\n",
        "    left_caudate_putamen_in_fmri_arr,\n",
        "    task_reg,\n",
        "    tr=2.0,\n",
        "    title=\"ROI signal vs task regressor\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fce32fa",
      "metadata": {
        "id": "0fce32fa"
      },
      "source": [
        "## 7) Slice timing correction (toy, interpolation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2542a2e",
      "metadata": {
        "id": "c2542a2e"
      },
      "outputs": [],
      "source": [
        "fmri_stc = slice_timing_correct(fmri, tr=2.0, slice_axis=2, interleaved=True, ref_slice=0)\n",
        "#Plot time series again after STC with time series before and after\n",
        "plot_roi_vs_design(\n",
        "    fmri_stc,\n",
        "    left_caudate_putamen_in_fmri_arr,\n",
        "    task_reg,\n",
        "    tr=2.0,\n",
        "    title=\"After slice-timing correction: ROI signal vs task regressor\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccaa789b",
      "metadata": {
        "id": "ccaa789b"
      },
      "source": [
        "## 8) Motion correction (toy translation via phase correlation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7d5a4b",
      "metadata": {
        "id": "9a7d5a4b"
      },
      "outputs": [],
      "source": [
        "plt.plot(mot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6866a7",
      "metadata": {
        "id": "0f6866a7"
      },
      "outputs": [],
      "source": [
        "fmri_mc, est_shifts = motion_correct_4d(fmri_stc, ref_index=0, brain_mask=brain_mask_for_fmri_arr)\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(est_shifts[:,0], label=\"dx\")\n",
        "plt.plot(est_shifts[:,1], label=\"dy\")\n",
        "plt.plot(est_shifts[:,2], label=\"dz\")\n",
        "plt.legend(); plt.title(\"Estimated sub-voxel shifts\"); plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d3b600d",
      "metadata": {
        "id": "0d3b600d"
      },
      "source": [
        "## 9) QC: FD + DVARS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcfdef9e",
      "metadata": {
        "id": "bcfdef9e"
      },
      "outputs": [],
      "source": [
        "def framewise_displacement(translations):\n",
        "    d = np.vstack([np.zeros((1,3)), np.diff(translations, axis=0)])\n",
        "    return np.abs(d).sum(axis=1)\n",
        "\n",
        "def dvars(fmri_4d, mask):\n",
        "    data = fmri_4d[mask > 0].astype(np.float64)  # (nvox, T)\n",
        "    diff = np.diff(data, axis=1)\n",
        "    return np.sqrt((diff**2).mean(axis=0))\n",
        "\n",
        "fd = framewise_displacement(est_shifts)\n",
        "dv = dvars(fmri_mc, brain_mask_for_fmri_arr)\n",
        "\n",
        "show_timeseries(fd, \"Framewise Displacement (translations-only, toy)\", ylabel=\"FD (vox)\")\n",
        "show_timeseries(dv, \"DVARS (toy)\", ylabel=\"DVARS (a.u.)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b9ead4d",
      "metadata": {
        "id": "4b9ead4d"
      },
      "source": [
        "## 10) Smoothing + filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4493d59c",
      "metadata": {
        "id": "4493d59c"
      },
      "outputs": [],
      "source": [
        "fmri_sm = spatial_smooth_4d(fmri_mc, fwhm_mm=6.0, voxel_size_mm=1.0)\n",
        "fmri_filt = filter_voxels(fmri_sm, brain_mask_for_fmri_arr, tr=2.0, low=0.01, high=0.12, max_vox=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d949950",
      "metadata": {
        "id": "2d949950"
      },
      "outputs": [],
      "source": [
        "plot_roi_vs_design(\n",
        "    fmri_stc,\n",
        "    left_caudate_putamen_in_fmri_arr,\n",
        "    task_reg,\n",
        "    tr=2.0,\n",
        "    title=\"After slice-timing correction: ROI signal vs task regressor\"\n",
        ")\n",
        "\n",
        "plot_roi_vs_design(\n",
        "    fmri_sm,\n",
        "    left_caudate_putamen_in_fmri_arr,\n",
        "    task_reg,\n",
        "    tr=2.0,\n",
        "    title=\"After Smoothing: ROI signal vs task regressor\"\n",
        ")\n",
        "\n",
        "plot_roi_vs_design(\n",
        "    fmri_filt,\n",
        "    left_caudate_putamen_in_fmri_arr,\n",
        "    task_reg,\n",
        "    tr=2.0,\n",
        "    title=\"After Filtering and Detrending: ROI signal vs task regressor\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84508471",
      "metadata": {
        "id": "84508471"
      },
      "source": [
        "## 11) Confounds regression (motion + WM/CSF + trends)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc3dc6a3",
      "metadata": {
        "id": "fc3dc6a3"
      },
      "outputs": [],
      "source": [
        "def extract_mean_ts(fmri_4d, mask):\n",
        "    v = fmri_4d[mask > 0]\n",
        "    return v.mean(axis=0)\n",
        "\n",
        "def regress_confounds(fmri_4d, mask, confounds):\n",
        "    X = np.column_stack([np.ones(confounds.shape[0]), confounds]).astype(np.float64)\n",
        "    XtX_inv = np.linalg.inv(X.T @ X)\n",
        "    P = X @ XtX_inv @ X.T  # (T,T)\n",
        "\n",
        "    data = fmri_4d[mask > 0].astype(np.float64)  # (nvox, T)\n",
        "    clean = data - (data @ P.T)\n",
        "    out = np.zeros_like(fmri_4d)\n",
        "    out[mask > 0] = clean.astype(np.float32)\n",
        "    return out\n",
        "\n",
        "\n",
        "wm_mask_for_fmri = ants.resample_image_to_target(\n",
        "    wm2t1_warped,\n",
        "    t1_downsample,\n",
        "    interp_type=0\n",
        ")\n",
        "wm_mask = wm_mask_for_fmri.numpy().astype(bool)\n",
        "\n",
        "csf_mask_for_fmri = ants.resample_image_to_target(\n",
        "    csf2t1_warped,\n",
        "    t1_downsample,\n",
        "    interp_type=0\n",
        ")\n",
        "csf_mask = csf_mask_for_fmri.numpy().astype(bool)\n",
        "\n",
        "\n",
        "wm_ts  = extract_mean_ts(fmri_sm, wm_mask)\n",
        "csf_ts = extract_mean_ts(fmri_sm, csf_mask)\n",
        "\n",
        "mot = est_shifts.astype(np.float64)\n",
        "mot_d = np.vstack([np.zeros((1,3)), np.diff(mot, axis=0)])\n",
        "\n",
        "t = np.linspace(-1, 1, fmri_sm.shape[-1])\n",
        "poly = np.column_stack([t, t**2])\n",
        "\n",
        "conf = np.column_stack([mot, mot_d, wm_ts, csf_ts, poly])\n",
        "fmri_clean = regress_confounds(fmri_sm, brain_mask_for_fmri_arr, conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289b6dfd",
      "metadata": {
        "id": "289b6dfd"
      },
      "outputs": [],
      "source": [
        "plot_roi_vs_design(\n",
        "    fmri_clean,\n",
        "    left_caudate_putamen_in_fmri_arr,\n",
        "    task_reg,\n",
        "    tr=2.0,\n",
        "    title=\"After Regressing motion, WM/CSF, trends: ROI signal vs task regressor\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52723ad5",
      "metadata": {
        "id": "52723ad5"
      },
      "source": [
        "## 12) Task GLM (beta + t-map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454c4403",
      "metadata": {
        "id": "454c4403"
      },
      "outputs": [],
      "source": [
        "def glm_fit_voxelwise(Y, X):\n",
        "    XtX_inv = np.linalg.inv(X.T @ X)\n",
        "    betas = (XtX_inv @ X.T @ Y.T).T\n",
        "    resid = Y - (betas @ X.T)\n",
        "    dof = X.shape[0] - X.shape[1]\n",
        "    sigma2 = (resid**2).sum(axis=1) / max(dof, 1)\n",
        "    return betas, sigma2, XtX_inv, dof\n",
        "\n",
        "X = np.column_stack([np.ones_like(task_reg), task_reg, mot, mot_d]).astype(np.float64)\n",
        "idx = np.where(brain_mask_for_fmri_arr > 0)\n",
        "Y = fmri_clean[idx[0], idx[1], idx[2], :].astype(np.float64)\n",
        "\n",
        "betas, sigma2, XtX_inv, dof = glm_fit_voxelwise(Y, X)\n",
        "se = np.sqrt(sigma2 * XtX_inv[1,1])\n",
        "tvals = betas[:,1] / (se + 1e-12)\n",
        "\n",
        "tmap = np.zeros(brain_mask_for_fmri_arr.shape, np.float32)\n",
        "tmap[idx] = tvals.astype(np.float32)\n",
        "show_slices(tmap[...,10:60], \"Task t-map (toy GLM)\", slice_step=10, cmap='jet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6fd6c7",
      "metadata": {
        "id": "ad6fd6c7"
      },
      "outputs": [],
      "source": [
        "tmap_img = ants.copy_image_info(t1_downsample, ants.from_numpy(tmap))\n",
        "# tmap_img[tmap_img.abs() < 10.0] = 0.0  # threshold for display\n",
        "t1_downsample.plot(axis=2, overlay=tmap_img, overlay_cmap='jet', overlay_alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0aa4d2a",
      "metadata": {
        "id": "b0aa4d2a"
      },
      "outputs": [],
      "source": [
        "pvals = 2 * (1 - t_dist.cdf(np.abs(tvals), df=dof))\n",
        "sig_fdr = fdr_bh(pvals, alpha=0.05)\n",
        "tmap_fdr_thresh = np.zeros(brain_mask_for_fmri_arr.shape, np.float32)\n",
        "tmap_fdr_thresh[idx] = np.where(sig_fdr, tvals, 0)\n",
        "tmap_fdr_img = ants.copy_image_info(t1_downsample, ants.from_numpy(tmap_fdr_thresh))\n",
        "t1_downsample.plot(axis=2, overlay=tmap_fdr_img, overlay_cmap='jet', overlay_alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ad1bf7",
      "metadata": {
        "id": "d5ad1bf7"
      },
      "source": [
        "## 13) Seed correlation map (resting-style connectivity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a398ffd5",
      "metadata": {
        "id": "a398ffd5"
      },
      "outputs": [],
      "source": [
        "seed = ndi.binary_dilation(left_caudate_putamen_in_fmri_arr, iterations=1).astype(np.uint8)\n",
        "corr_map = seed_correlation_map(fmri_clean, seed, brain_mask_for_fmri_arr)\n",
        "corr_map_img = ants.copy_image_info(t1_downsample, ants.from_numpy(corr_map))\n",
        "t1_downsample.plot(axis=2, overlay=corr_map_img, overlay_cmap='hot', overlay_alpha=0.5)\n",
        "corr_map_img[corr_map_img < 0.5] = 0.0  # threshold for display\n",
        "t1_downsample.plot(axis=2, overlay=corr_map_img, overlay_cmap='hot', overlay_alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18dcb0c0",
      "metadata": {
        "id": "18dcb0c0"
      },
      "outputs": [],
      "source": [
        "aal_atlas = get_nii(url = \"https://media.githubusercontent.com/media/willi3by/systems_biology_neuroimaging_lecture/main/AAL3v1_1mm.nii.gz\",\n",
        "                    local_fname='Test_aal.nii.gz')[0]\n",
        "\n",
        "aal_to_t1 = ants.apply_transforms(\n",
        "    fixed=t1_debiased_denoised,\n",
        "    moving=aal_atlas,\n",
        "    transformlist=mni2t1['fwdtransforms'],\n",
        "    interpolator='nearestNeighbor'\n",
        ")\n",
        "\n",
        "aal_for_fmri = ants.resample_image_to_target(\n",
        "    aal_to_t1,\n",
        "    t1_downsample,\n",
        "    interp_type=0\n",
        ")\n",
        "\n",
        "aal_for_fmri_arr = aal_for_fmri.numpy().astype(np.int16) * brain_mask_for_fmri_arr.astype(np.int16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a167586a",
      "metadata": {
        "id": "a167586a"
      },
      "outputs": [],
      "source": [
        "mni_img.plot(axis=2, overlay=aal_atlas, overlay_alpha=0.5, overlay_cmap='jet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef36f11",
      "metadata": {
        "id": "0ef36f11"
      },
      "outputs": [],
      "source": [
        "#Extract time series for each AAL region\n",
        "n_regions = len(np.unique(aal_for_fmri_arr)) - 1  # exclude 0\n",
        "region_idxs = np.unique(aal_for_fmri_arr)[1:]  # exclude 0\n",
        "region_ts = []\n",
        "for r in region_idxs:\n",
        "    region_mask = (aal_for_fmri_arr == r)\n",
        "    if np.sum(region_mask) == 0:\n",
        "        continue\n",
        "    region_ts.append(extract_mean_ts(fmri_clean, region_mask))\n",
        "region_ts = np.array(region_ts)  # (n_regions, T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ff5a61",
      "metadata": {
        "id": "c4ff5a61"
      },
      "outputs": [],
      "source": [
        "#Compute region-to-region correlation matrix\n",
        "corr_matrix = np.corrcoef(region_ts)\n",
        "np.fill_diagonal(corr_matrix, 0)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(corr_matrix, vmin=-1, vmax=1, cmap='bwr')\n",
        "plt.colorbar(label='Correlation')\n",
        "plt.title('Region-to-Region Correlation Matrix (AAL)')\n",
        "plt.xlabel('Region Index')\n",
        "plt.ylabel('Region Index')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f638c1",
      "metadata": {
        "id": "94f638c1"
      },
      "outputs": [],
      "source": [
        "corr_matrix_thresh = np.where(np.abs(corr_matrix) >= 0.75, 1, 0)\n",
        "plt.figure(figsize=(8,8))\n",
        "#Plot thresholded correlation matrix with 0 as white and 1 as black\n",
        "plt.imshow(corr_matrix_thresh, cmap='gray_r', alpha=0.8)\n",
        "plt.title('Thresholded Correlation Matrix (|r| >= 0.5)')\n",
        "plt.xlabel('Region Index')\n",
        "plt.ylabel('Region Index')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb320f4c",
      "metadata": {
        "id": "cb320f4c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}